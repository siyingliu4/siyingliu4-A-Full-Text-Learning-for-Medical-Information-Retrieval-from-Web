{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF schema1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf, df, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def dic_(allDocument): # alldocument=collection: list\n",
    "    long_str = \" \".join(allDocument)\n",
    "    b=list(set(list(long_str.split())))\n",
    "    return sorted(b)\n",
    "\n",
    "def tf_(doc_que): # term frequqency\n",
    "    counts = Counter(list(doc_que.split()))\n",
    "    return dict(counts)\n",
    "\n",
    "def df_(term, allDocuments):  # df: no. of occurance of a term in whole collection\n",
    "    dic=dict.fromkeys(term, 0)\n",
    "    for i in allDocuments:\n",
    "        n=0\n",
    "        for word in term:\n",
    "            if word in i.split():         \n",
    "                dic[word]=dic[word]+1\n",
    "            n+=1  \n",
    "    return dic  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf for doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def tfidf_(query_s,c,df,allDocument): # query_s: Series (df['col']), allDocument:list\n",
    "    \n",
    "    all_tfidf=[]\n",
    "    for query in query_s:\n",
    "        q_tf=tf_(query)\n",
    "        mac=q_tf.values()\n",
    "        max_tf=max(q_tf.values())\n",
    "        tfidf=[]\n",
    "        for word in c:\n",
    "            if word not in q_tf: # query item does not shown in doc collection\n",
    "                    value=0\n",
    "            else:\n",
    "                value=(1+math.log10(q_tf.get(word)))/(1+math.log10(max_tf))*math.log10(len(allDocument)/df.get(word))\n",
    "           \n",
    "            tfidf.append(value)\n",
    "        all_tfidf.append(tfidf)\n",
    "    return np.array(all_tfidf) #vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf_q(query_s,c,df,allDocument): # query_s: Series (df['col']), allDocument:list\n",
    "    \n",
    "    all_tfidf=[]\n",
    "    for query in query_s:\n",
    "        q_tf=tf_(query)\n",
    "        mac=q_tf.values()\n",
    "        max_tf=max(q_tf.values())\n",
    "        tfidf=[]\n",
    "        for word in c:\n",
    "            if word not in q_tf: # query item does not shown in doc collection\n",
    "                    value=0\n",
    "            else:\n",
    "                value=q_tf.get(word)\n",
    "           \n",
    "            tfidf.append(value)\n",
    "        all_tfidf.append(tfidf)\n",
    "    return np.array(all_tfidf) #vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_query=pd.read_excel('df_query_pre.xlsx')\n",
    "df_doc=pd.read_excel('df_doc_pre.xlsx')\n",
    "\n",
    "doc_col=df_doc.loc[: , \"Text_tok\"].tolist() #collection: list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dictionary & document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic_df=pd.read_csv('dictionary.csv')\n",
    "doc_fre_df=pd.read_csv('document_frequency.csv')\n",
    "\n",
    "dic=dic_df['0'].tolist()\n",
    "doc_fre=pd.Series(doc_fre_df.df.values,index=doc_fre_df.term).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.3126003742218\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "q_tfidf=tfidf_q(df_query[\"Text_tok\"],dic,doc_fre,doc_col) # query tf-idf\n",
    "d_tfidf=tfidf_(df_doc[\"Text_tok\"],dic,doc_fre,doc_col) # doc tf-idf\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)   # seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: consine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1157.573005437851\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "sim_all={}\n",
    "for q in range(len(q_tfidf)):\n",
    "    sim={}\n",
    "    sim_all[q]=sim\n",
    "    \n",
    "    for d in range(len(d_tfidf)):\n",
    "        sim[d]=cosine_similarity(d_tfidf[d],q_tfidf[q])\n",
    "    #print(sim)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_similarity= pd.DataFrame(data=sim_all)\n",
    "df_similarity['d_index']=df_similarity.index\n",
    "df1 = df_similarity.reset_index(drop=True)\n",
    "df2 = pd.melt(df1, id_vars=[\"d_index\"], var_name=\"q_index\", value_name=\"similarity\")\n",
    "df2=df2.sort_values(by=['q_index','similarity'],ascending=[True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_query['q_index']=df_query.index\n",
    "df_doc['d_index']=df_doc.index\n",
    "df2=pd.merge(df2,df_query[['Query id','q_index']],on='q_index',how='left')\n",
    "df2=pd.merge(df2,df_doc[['Doc id','d_index']],on='d_index',how='left')\n",
    "df_similarity_final=df2[['Query id', 'Doc id', 'similarity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel_label = pd.read_excel(\"all2-1-0.qrel.xlsx\")\n",
    "rel_similarity=pd.merge(df_similarity_final[['Query id','Doc id']],rel_label, on=['Query id','Doc id'], how='left')\n",
    "rel_similarity=rel_similarity.fillna(value=0)\n",
    "rel_similarity=rel_similarity.drop(['Doc id'],axis=1)\n",
    "s = rel_similarity.groupby('Query id')['Rel_level'].apply(lambda x: x.tolist())\n",
    "correct_input=s.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10479293051214097\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "# presicion \n",
    "def precision(y_true):\n",
    "#y_true: this list reordered y_true list\n",
    "    p=[]\n",
    "    a=0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i]==1:\n",
    "            a+=1\n",
    "            precision=a/(i+1)\n",
    "            p.append(precision)\n",
    "    #print(p)\n",
    "    return p\n",
    "\n",
    "# average precision\n",
    "def AP(y_true):\n",
    "    p=precision(y_true)\n",
    "    if len(p)!=0:\n",
    "        AP=sum(p)/len(p)\n",
    "    else:\n",
    "        AP=0\n",
    "    #print(AP)\n",
    "    return AP\n",
    "\n",
    "\n",
    "def MAP(list_true):# query list \n",
    "    ap=[]\n",
    "    for i in range(len(list_true)):\n",
    "        ap.append(AP(list_true[i]))\n",
    "    total=sum(ap)\n",
    "    #print(ap)\n",
    "    return total/(len(list_true))\n",
    "\n",
    "print(MAP(correct_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nDCG1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def ndcg1(correct):\n",
    "    dcg=0\n",
    "    for i in range(len(correct)):\n",
    "        gain=2**correct[i]-1\n",
    "        discounts=np.log2(i+2)\n",
    "        dcg=dcg+gain/discounts\n",
    "    \n",
    "    #idcg\n",
    "    order = np.argsort(correct)\n",
    "    sort_correct = np.take(correct, order[::-1])\n",
    "    idcg=0\n",
    "    for i in range(len(sort_correct)):\n",
    "        gain=2**sort_correct[i]-1\n",
    "        discounts=np.log2(i+2)\n",
    "        idcg=idcg+gain/discounts\n",
    "    #print(dcg)\n",
    "    #print(idcg)\n",
    "    return dcg/idcg\n",
    "\n",
    "def mean_ndcg1(correct_list):\n",
    "    b=0\n",
    "    for correct in correct_list:\n",
    "        a=ndcg1(correct)\n",
    "        b=b+a\n",
    "    return b/len(correct_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### nDCG2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ndcg2(correct):\n",
    "    dcg=0\n",
    "    for i in range(len(correct)):\n",
    "        gain=correct[i]\n",
    "        discounts=np.log2(i+2)\n",
    "        dcg=dcg+gain/discounts\n",
    "    \n",
    "    #idcg\n",
    "    order = np.argsort(correct)\n",
    "    sort_correct = np.take(correct, order[::-1])\n",
    "    idcg=0\n",
    "    for i in range(len(sort_correct)):\n",
    "        gain=sort_correct[i]\n",
    "        discounts=np.log2(i+2)\n",
    "        idcg=idcg+gain/discounts\n",
    "    #print(dcg)\n",
    "    #print(idcg)\n",
    "    return dcg/idcg\n",
    "\n",
    "def mean_ndcg2(correct_list):\n",
    "    b=0\n",
    "    for correct in correct_list:\n",
    "        a=ndcg2(correct)\n",
    "        b=b+a\n",
    "    return b/len(correct_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG1: 0.462497814358\n",
      "nDCG2: 0.463085521775\n"
     ]
    }
   ],
   "source": [
    "print('nDCG1:',mean_ndcg1(correct_input))\n",
    "print('nDCG2:',mean_ndcg2(correct_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
