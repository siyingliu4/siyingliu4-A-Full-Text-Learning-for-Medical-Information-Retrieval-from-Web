{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-clustering with single_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf, df, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def dic_(allDocument): # alldocument=collection: list\n",
    "    long_str = \" \".join(allDocument)\n",
    "    b=list(set(list(long_str.split())))\n",
    "    return sorted(b)\n",
    "\n",
    "def tf_(doc_que): # term frequency\n",
    "    counts = Counter(list(doc_que.split()))\n",
    "    return dict(counts)\n",
    "\n",
    "def df_(term, allDocuments):  # df: no. of occurance of a term in whole collection\n",
    "    dic=dict.fromkeys(term, 0)\n",
    "    for i in allDocuments:\n",
    "        n=0\n",
    "        for word in term:\n",
    "            if word in i.split():         \n",
    "                dic[word]=dic[word]+1\n",
    "            n+=1  \n",
    "    return dic  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def tfidf_(query_s,c,df,allDocument): # query_s: Series (df['col']), allDocument:list\n",
    "\n",
    "    all_tfidf=[]\n",
    "    for query in query_s:\n",
    "        q_tf=tf_(query)\n",
    "        max_tf=max(q_tf.values())\n",
    "        tfidf=[]\n",
    "        for word in c:\n",
    "            if word not in q_tf: # query item does not shown in doc collection\n",
    "                    value=0\n",
    "            else:\n",
    "                value=(1+math.log10(q_tf.get(word)))/(1+math.log10(max_tf))*math.log10(len(allDocument)/df.get(word))\n",
    "            tfidf.append(value)\n",
    "        all_tfidf.append(tfidf)\n",
    "    return np.array(all_tfidf) #vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_doc=pd.read_excel('df_doc_pre.xlsx')\n",
    "df_query=pd.read_excel('df_query_pre.xlsx')\n",
    "\n",
    "doc_col=df_doc.loc[: , \"Text_tok\"].tolist() #collection: list\n",
    "\n",
    "dic_df=pd.read_csv('dictionary.csv')\n",
    "doc_fre_df=pd.read_csv('document_frequency.csv')\n",
    "dic=dic_df['0'].tolist()\n",
    "doc_fre=pd.Series(doc_fre_df.df.values,index=doc_fre_df.term).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tfidf=tfidf_(df_doc[\"Text_tok\"],dic,doc_fre,doc_col) # doc tf-idf\n",
    "q_tfidf=tfidf_(df_query[\"Text_tok\"],dic,doc_fre,doc_col) # query tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doc clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import operator\n",
    "import operator\n",
    "import time\n",
    "\n",
    "def pre_clustering(d_tfidf,ran_seed,leader_size):\n",
    "    \n",
    "    # randomly select k doc leaders\n",
    "    np.random.seed(seed=ran_seed)\n",
    "    idx = np.random.randint(len(df_doc), size=leader_size)\n",
    "    leader=d_tfidf[idx,:]\n",
    "\n",
    "    # assign each doc in nearest clusters\n",
    "    cluster_label=[]\n",
    "    for doc in range(len(d_tfidf)):\n",
    "        similarity=[]\n",
    "        for l in range(len(leader)):\n",
    "            sim=cosine_similarity(d_tfidf[doc],leader[l])\n",
    "            similarity.append(sim)\n",
    "        cluster_label.append(np.argmax(similarity))\n",
    "    df_d_tfidf = pd.DataFrame(d_tfidf)\n",
    "    df_d_tfidf['label']=cluster_label\n",
    "    return leader, df_d_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "import time\n",
    "\n",
    "def cosSimilarityImp(q_tfidf,leader,df_d_tfidf):\n",
    "    \n",
    "    start = time.time()\n",
    "    sim_all={}\n",
    "    for q in range(len(q_tfidf)):\n",
    "        leader_sim={}\n",
    "        sim={}\n",
    "        sim_all[q]=sim\n",
    "        \n",
    "        # compare similarity between query and doc leaders\n",
    "        for l in range(len(leader)):\n",
    "            leader_sim[l]=cosine_similarity(leader[l],q_tfidf[q])\n",
    "        \n",
    "        # access the cloest leader's cluster\n",
    "        closest_cluster_label=max(leader_sim.items(), key=operator.itemgetter(1))[0]\n",
    "        closest_cluster=df_d_tfidf.loc[df_d_tfidf['label'] == closest_cluster_label].drop(['label'],axis=1)\n",
    "        \n",
    "        # calculate similarity amongth docs in the cloest cluster\n",
    "        for d in closest_cluster.index:\n",
    "            sim[d]=cosine_similarity(closest_cluster.loc[d],q_tfidf[q])\n",
    "\n",
    "    end = time.time()\n",
    "    print('similarity time: ',end - start)\n",
    "\n",
    "    # ranking doc by similartiy\n",
    "    # covert format to a table\n",
    "    df_similarity= pd.DataFrame(data=sim_all)\n",
    "    df_similarity['d_index']=df_similarity.index\n",
    "    df1 = df_similarity.reset_index(drop=True)\n",
    "    df2 = pd.melt(df1, id_vars=[\"d_index\"], var_name=\"q_index\", value_name=\"similarity\")\n",
    "    df2=df2.sort_values(by=['q_index','similarity'],ascending=[True,False])\n",
    "\n",
    "    df_query['q_index']=df_query.index\n",
    "    df_doc['d_index']=df_doc.index\n",
    "    df2=pd.merge(df2,df_query[['Query id','q_index']],on='q_index',how='left')\n",
    "    df2=pd.merge(df2,df_doc[['Doc id','d_index']],on='d_index',how='left')\n",
    "    df_similarity_final=df2[['Query id', 'Doc id', 'similarity']]\n",
    "    df_similarity_final=df_similarity_final.dropna()\n",
    "\n",
    "    # prepare format for meaturement\n",
    "    rel_label = pd.read_excel(\"all2-1-0.qrel.xlsx\")\n",
    "    rel_similarity=pd.merge(df_similarity_final[['Query id','Doc id']],rel_label, on=['Query id','Doc id'], how='left')\n",
    "    rel_similarity=rel_similarity.fillna(value=0)\n",
    "    rel_similarity=rel_similarity.drop(['Doc id'],axis=1)\n",
    "    s = rel_similarity.groupby('Query id')['Rel_level'].apply(lambda x: x.tolist())\n",
    "    correct_input=s.values\n",
    "\n",
    "    return correct_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# presicion \n",
    "def precision(y_true):\n",
    "#y_true: this list reordered y_true list\n",
    "    p=[]\n",
    "    a=0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i]==1:\n",
    "            a+=1\n",
    "            precision=a/(i+1)\n",
    "            p.append(precision)\n",
    "    #print(p)\n",
    "    return p\n",
    "\n",
    "# average precision\n",
    "def AP(y_true):\n",
    "    p=precision(y_true)\n",
    "    if len(p)!=0:\n",
    "        AP=sum(p)/len(p)\n",
    "    else:\n",
    "        AP=0\n",
    "    #print(AP)\n",
    "    return AP\n",
    "\n",
    "\n",
    "def MAP(list_true):# query list \n",
    "    ap=[]\n",
    "    for i in range(len(list_true)):\n",
    "        ap.append(AP(list_true[i]))\n",
    "    total=sum(ap)\n",
    "    #print(ap)\n",
    "    return total/(len(list_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nDCG1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def ndcg1(correct):\n",
    "    if sum(correct)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        dcg=0\n",
    "        for i in range(len(correct)):\n",
    "            gain=2**correct[i]-1\n",
    "            discounts=np.log2(i+2)\n",
    "            dcg=dcg+gain/discounts\n",
    "    \n",
    "        #idcg\n",
    "        order = np.argsort(correct)\n",
    "        sort_correct = np.take(correct, order[::-1])\n",
    "        idcg=0\n",
    "        for i in range(len(sort_correct)):\n",
    "            gain=2**sort_correct[i]-1\n",
    "            discounts=np.log2(i+2)\n",
    "            idcg=idcg+gain/discounts\n",
    "        #print(dcg)\n",
    "        #print(idcg)\n",
    "        return dcg/idcg\n",
    "\n",
    "def mean_ndcg1(correct_list):\n",
    "    b=0\n",
    "    for correct in correct_list:\n",
    "        a=ndcg1(correct)\n",
    "        b=b+a\n",
    "    return b/len(correct_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leader size: 73\n",
      "seed: 0\n",
      "similarity time:  127.22980046272278\n",
      "MAP: 0.12213382215123987\n",
      "nDCG: 0.255696736928\n",
      "\n",
      "seed: 1\n",
      "similarity time:  140.3204002380371\n",
      "MAP: 0.1349435507081836\n",
      "nDCG: 0.281596613068\n",
      "\n",
      "seed: 2\n",
      "similarity time:  121.02650022506714\n",
      "MAP: 0.13353519383144877\n",
      "nDCG: 0.270695401174\n",
      "\n",
      "seed: 3\n",
      "similarity time:  160.1100001335144\n",
      "MAP: 0.13324585229511968\n",
      "nDCG: 0.286548144426\n",
      "\n",
      "seed: 4\n",
      "similarity time:  122.78949999809265\n",
      "MAP: 0.13338996447708998\n",
      "nDCG: 0.27539129887\n",
      "\n",
      "seed: 5\n",
      "similarity time:  135.7315001487732\n",
      "MAP: 0.13807766274347116\n",
      "nDCG: 0.28411638356\n",
      "\n",
      "seed: 6\n",
      "similarity time:  113.21399974822998\n",
      "MAP: 0.12625873150058353\n",
      "nDCG: 0.266347565774\n",
      "\n",
      "seed: 7\n",
      "similarity time:  129.4967999458313\n",
      "MAP: 0.1262757659116349\n",
      "nDCG: 0.258539190864\n",
      "\n",
      "seed: 8\n",
      "similarity time:  119.04699969291687\n",
      "MAP: 0.13523005144959838\n",
      "nDCG: 0.273715481787\n",
      "\n",
      "seed: 9\n",
      "similarity time:  130.76550006866455\n",
      "MAP: 0.136884728870111\n",
      "nDCG: 0.276464758563\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leader_size=round(math.sqrt(len(df_doc)))\n",
    "print ('leader size:',leader_size)\n",
    "for i in range(0,10):\n",
    "    print('seed:',i)\n",
    "    cluster=pre_clustering(d_tfidf,i,leader_size)\n",
    "    result=cosSimilarityImp(q_tfidf,cluster[0], cluster[1])\n",
    "    print('MAP:',MAP(result)) \n",
    "    print('nDCG:',mean_ndcg1(result))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leader size: 60\n",
      "seed: 0\n",
      "similarity time:  146.79850029945374\n",
      "MAP: 0.1289793572917648\n",
      "nDCG: 0.271957723819\n",
      "\n",
      "seed: 1\n",
      "similarity time:  161.9119999408722\n",
      "MAP: 0.13729110280673482\n",
      "nDCG: 0.289487553414\n",
      "\n",
      "seed: 2\n",
      "similarity time:  142.19200015068054\n",
      "MAP: 0.13075629364057956\n",
      "nDCG: 0.269584632975\n",
      "\n",
      "seed: 3\n",
      "similarity time:  172.69200015068054\n",
      "MAP: 0.13426807434952176\n",
      "nDCG: 0.291898533734\n",
      "\n",
      "seed: 4\n",
      "similarity time:  141.3510000705719\n",
      "MAP: 0.13127186311128997\n",
      "nDCG: 0.271995830929\n",
      "\n",
      "seed: 5\n",
      "similarity time:  139.9500002861023\n",
      "MAP: 0.13865997054371132\n",
      "nDCG: 0.284499770374\n",
      "\n",
      "seed: 6\n",
      "similarity time:  141.6190001964569\n",
      "MAP: 0.12681425648750969\n",
      "nDCG: 0.275090256543\n",
      "\n",
      "seed: 7\n",
      "similarity time:  133.19999980926514\n",
      "MAP: 0.12434432015813864\n",
      "nDCG: 0.261795457316\n",
      "\n",
      "seed: 8\n",
      "similarity time:  137.21299982070923\n",
      "MAP: 0.13026761269351653\n",
      "nDCG: 0.272355668592\n",
      "\n",
      "seed: 9\n",
      "similarity time:  141.07800006866455\n",
      "MAP: 0.13128755208197948\n",
      "nDCG: 0.274356030634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leader_size=60\n",
    "print ('leader size:',leader_size)\n",
    "for i in range(0,10):\n",
    "    print('seed:',i)\n",
    "    cluster=pre_clustering(d_tfidf,i,leader_size)\n",
    "    result=cosSimilarityImp(q_tfidf,cluster[0], cluster[1])\n",
    "    print('MAP:',MAP(result)) \n",
    "    print('nDCG:',mean_ndcg1(result))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### According several testing by randomly selecting 10 times (seed 0-10), random seed 5 always gets best performance on both MAP and nDCG. Hence folllwing leader sizes just show resultes where random seed=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leader size: 70\n",
      "similarity time:  141.71440076828003\n",
      "MAP: 0.13805103992517584\n",
      "nDCG: 0.284927751445\n",
      "\n",
      "leader size: 80\n",
      "similarity time:  121.0858006477356\n",
      "MAP: 0.13905014154891845\n",
      "nDCG: 0.281681723324\n",
      "\n",
      "leader size: 90\n",
      "similarity time:  113.0476005077362\n",
      "MAP: 0.14044409830472898\n",
      "nDCG: 0.283476843559\n",
      "\n",
      "leader size: 100\n",
      "similarity time:  105.67640042304993\n",
      "MAP: 0.143367708954208\n",
      "nDCG: 0.285419378428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leader_size=[70,80,90,100]\n",
    "for i in leader_size:\n",
    "    print('leader size:',i)\n",
    "    cluster=pre_clustering(d_tfidf,5,i)\n",
    "    result=cosSimilarityImp(q_tfidf,cluster[0], cluster[1])\n",
    "    print('MAP:',MAP(result)) \n",
    "    print('nDCG:',mean_ndcg1(result))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leader size: 110\n",
      "similarity time:  103.31860041618347\n",
      "MAP: 0.1470512678039042\n",
      "nDCG: 0.287821564374\n",
      "\n",
      "leader size: 120\n",
      "similarity time:  91.81780076026917\n",
      "MAP: 0.14466108633093622\n",
      "nDCG: 0.27836094075\n",
      "\n",
      "leader size: 130\n",
      "similarity time:  89.41680073738098\n",
      "MAP: 0.14875273281095916\n",
      "nDCG: 0.285419812568\n",
      "\n",
      "leader size: 140\n",
      "similarity time:  85.92140054702759\n",
      "MAP: 0.14383869258857993\n",
      "nDCG: 0.278566136649\n",
      "\n",
      "leader size: 150\n",
      "similarity time:  94.16780018806458\n",
      "MAP: 0.14646628526442337\n",
      "nDCG: 0.280998590601\n",
      "\n",
      "leader size: 160\n",
      "similarity time:  82.15600061416626\n",
      "MAP: 0.1485848039624784\n",
      "nDCG: 0.281915978697\n",
      "\n",
      "leader size: 170\n",
      "similarity time:  85.99080014228821\n",
      "MAP: 0.15444079854033713\n",
      "nDCG: 0.287963616946\n",
      "\n",
      "leader size: 180\n",
      "similarity time:  77.13320064544678\n",
      "MAP: 0.15613003085810598\n",
      "nDCG: 0.288534829529\n",
      "\n",
      "leader size: 190\n",
      "similarity time:  76.49020051956177\n",
      "MAP: 0.15754416557508139\n",
      "nDCG: 0.290814047674\n",
      "\n",
      "leader size: 200\n",
      "similarity time:  75.59540033340454\n",
      "MAP: 0.1586135731121029\n",
      "nDCG: 0.291161126485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leader_size=[110,120,130,140,150,160,170,180,190,200]\n",
    "for i in leader_size:\n",
    "    print('leader size:',i)\n",
    "    cluster=pre_clustering(d_tfidf,5,i)\n",
    "    result=cosSimilarityImp(q_tfidf,cluster[0], cluster[1])\n",
    "    print('MAP:',MAP(result)) \n",
    "    print('nDCG:',mean_ndcg1(result))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leader size: 210\n",
      "similarity time:  74.89780020713806\n",
      "MAP: 0.1582693973645075\n",
      "nDCG: 0.289886740245\n",
      "\n",
      "leader size: 220\n",
      "similarity time:  72.72300028800964\n",
      "MAP: 0.15804443930767945\n",
      "nDCG: 0.287432426277\n",
      "\n",
      "leader size: 230\n",
      "similarity time:  71.86300039291382\n",
      "MAP: 0.15887640931101688\n",
      "nDCG: 0.28734083912\n",
      "\n",
      "leader size: 240\n",
      "similarity time:  69.05020046234131\n",
      "MAP: 0.1617518084002558\n",
      "nDCG: 0.290836234403\n",
      "\n",
      "leader size: 250\n",
      "similarity time:  73.5400002002716\n",
      "MAP: 0.16201863658825524\n",
      "nDCG: 0.292049485657\n",
      "\n",
      "leader size: 260\n",
      "similarity time:  72.32980012893677\n",
      "MAP: 0.1634345442103171\n",
      "nDCG: 0.292123967807\n",
      "\n",
      "leader size: 270\n",
      "similarity time:  71.19659996032715\n",
      "MAP: 0.1642988781011992\n",
      "nDCG: 0.294825693516\n",
      "\n",
      "leader size: 280\n",
      "similarity time:  71.55020046234131\n",
      "MAP: 0.16372902737635864\n",
      "nDCG: 0.295395115316\n",
      "\n",
      "leader size: 290\n",
      "similarity time:  67.16999983787537\n",
      "MAP: 0.16236967730495142\n",
      "nDCG: 0.286064486353\n",
      "\n",
      "leader size: 300\n",
      "similarity time:  67.04900002479553\n",
      "MAP: 0.16370248149143202\n",
      "nDCG: 0.286583929385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leader_size=[210,220,230,240,250,260,270,280,290,300]\n",
    "for i in leader_size:\n",
    "    print('leader size:',i)\n",
    "    cluster=pre_clustering(d_tfidf,5,i)\n",
    "    result=cosSimilarityImp(q_tfidf,cluster[0], cluster[1])\n",
    "    print('MAP:',MAP(result)) \n",
    "    print('nDCG:',mean_ndcg1(result))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leader size: 310\n",
      "similarity time:  66.7170000076294\n",
      "MAP: 0.16317170324500974\n",
      "nDCG: 0.285673307332\n",
      "\n",
      "leader size: 320\n",
      "similarity time:  67.15899991989136\n",
      "MAP: 0.1620768555177003\n",
      "nDCG: 0.284783203314\n",
      "\n",
      "leader size: 330\n",
      "similarity time:  72.75140023231506\n",
      "MAP: 0.16238091326897536\n",
      "nDCG: 0.284918787628\n",
      "\n",
      "leader size: 340\n",
      "similarity time:  66.04580044746399\n",
      "MAP: 0.1610115262904186\n",
      "nDCG: 0.283931420737\n",
      "\n",
      "leader size: 350\n",
      "similarity time:  66.87140035629272\n",
      "MAP: 0.16092495578398236\n",
      "nDCG: 0.283896375867\n",
      "\n",
      "leader size: 360\n",
      "similarity time:  67.76360034942627\n",
      "MAP: 0.16220567353906876\n",
      "nDCG: 0.287335571432\n",
      "\n",
      "leader size: 370\n",
      "similarity time:  70.21800017356873\n",
      "MAP: 0.1624075345563928\n",
      "nDCG: 0.286754882049\n",
      "\n",
      "leader size: 380\n",
      "similarity time:  70.42580032348633\n",
      "MAP: 0.16258939217715676\n",
      "nDCG: 0.286265221808\n",
      "\n",
      "leader size: 390\n",
      "similarity time:  67.93600010871887\n",
      "MAP: 0.16406954929865916\n",
      "nDCG: 0.286451156625\n",
      "\n",
      "leader size: 400\n",
      "similarity time:  68.15900039672852\n",
      "MAP: 0.16374104206812654\n",
      "nDCG: 0.285050192658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leader_size=[310,320,330,340,350,360,370,380,390,400]\n",
    "for i in leader_size:\n",
    "    print('leader size:',i)\n",
    "    cluster=pre_clustering(d_tfidf,5,i)\n",
    "    result=cosSimilarityImp(q_tfidf,cluster[0], cluster[1])\n",
    "    print('MAP:',MAP(result)) \n",
    "    print('nDCG:',mean_ndcg1(result))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leader size: 500\n",
      "similarity time:  73.0264003276825\n",
      "MAP: 0.1730123956244614\n",
      "nDCG: 0.297407110871\n",
      "\n",
      "leader size: 600\n",
      "similarity time:  77.23060059547424\n",
      "MAP: 0.18996214310238826\n",
      "nDCG: 0.314291608949\n",
      "\n",
      "leader size: 700\n",
      "similarity time:  90.51080083847046\n",
      "MAP: 0.1899768685810404\n",
      "nDCG: 0.31189783066\n",
      "\n",
      "leader size: 800\n",
      "similarity time:  92.22960042953491\n",
      "MAP: 0.18928394248608627\n",
      "nDCG: 0.311180117751\n",
      "\n",
      "leader size: 900\n",
      "similarity time:  101.96960067749023\n",
      "MAP: 0.1881944374961413\n",
      "nDCG: 0.303194067397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leader_size=[500,600,700,800,900]\n",
    "for i in leader_size:\n",
    "    print('leader size:',i)\n",
    "    cluster=pre_clustering(d_tfidf,5,i)\n",
    "    result=cosSimilarityImp(q_tfidf,cluster[0], cluster[1])\n",
    "    print('MAP:',MAP(result)) \n",
    "    print('nDCG:',mean_ndcg1(result))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leader size: 1000\n",
      "similarity time:  105.09270071983337\n",
      "MAP: 0.18664047565763092\n",
      "nDCG: 0.303532309349\n",
      "\n",
      "leader size: 2000\n",
      "similarity time:  190.89420104026794\n",
      "MAP: 0.21611770194783586\n",
      "nDCG: 0.347978502737\n",
      "\n",
      "leader size: 3000\n",
      "similarity time:  290.0717010498047\n",
      "MAP: 0.23696130530611353\n",
      "nDCG: 0.374775525992\n",
      "\n",
      "leader size: 4000\n",
      "similarity time:  387.80940103530884\n",
      "MAP: 0.23872536544223358\n",
      "nDCG: 0.381866978758\n",
      "\n",
      "leader size: 5000\n",
      "similarity time:  464.80210280418396\n",
      "MAP: 0.23737836572173973\n",
      "nDCG: 0.379830011557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leader_size=[1000,2000,3000,4000,5000]\n",
    "for i in leader_size:\n",
    "    print('leader size:',i)\n",
    "    cluster=pre_clustering(d_tfidf,5,i)\n",
    "    result=cosSimilarityImp(q_tfidf,cluster[0], cluster[1])\n",
    "    print('MAP:',MAP(result)) \n",
    "    print('nDCG:',mean_ndcg1(result))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leader size: 10\n",
      "similarity time:  831.9860045909882\n",
      "MAP: 0.12810915416478694\n",
      "nDCG: 0.342973212443\n",
      "\n",
      "leader size: 20\n",
      "similarity time:  347.59200167655945\n",
      "MAP: 0.13334874095601448\n",
      "nDCG: 0.321845271296\n",
      "\n",
      "leader size: 30\n",
      "similarity time:  252.3130009174347\n",
      "MAP: 0.13892417795463372\n",
      "nDCG: 0.311750251888\n",
      "\n",
      "leader size: 40\n",
      "similarity time:  230.63340067863464\n",
      "MAP: 0.14358346922999604\n",
      "nDCG: 0.309598759347\n",
      "\n",
      "leader size: 50\n",
      "similarity time:  198.74700093269348\n",
      "MAP: 0.14040385718822582\n",
      "nDCG: 0.291477312661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leader_size=[10,20,30,40,50]\n",
    "for i in leader_size:\n",
    "    print('leader size:',i)\n",
    "    cluster=pre_clustering(d_tfidf,5,i)\n",
    "    result=cosSimilarityImp(q_tfidf,cluster[0], cluster[1])\n",
    "    print('MAP:',MAP(result)) \n",
    "    print('nDCG:',mean_ndcg1(result))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
