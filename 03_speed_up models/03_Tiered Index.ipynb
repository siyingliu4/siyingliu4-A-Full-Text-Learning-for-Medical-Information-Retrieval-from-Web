{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def dic_(allDocument): # alldocument=collection: list\n",
    "    long_str = \" \".join(allDocument)\n",
    "    b=list(set(list(long_str.split())))\n",
    "    return sorted(b)\n",
    "\n",
    "def tf_(doc_que):\n",
    "    counts = Counter(list(doc_que.split()))\n",
    "    return dict(counts)\n",
    "\n",
    "def df_(term, allDocuments):  # df: no. of occurance of a term in whole collection\n",
    "    dic=dict.fromkeys(term, 0)\n",
    "    for i in allDocuments:\n",
    "        n=0\n",
    "        for word in term:\n",
    "            if word in i.split():         \n",
    "                dic[word]=dic[word]+1\n",
    "            n+=1  \n",
    "    return dic  \n",
    "import math\n",
    "\n",
    "def tfidf_(query_s,c,df,allDocument): # query_s: Series (df['col']), allDocument:list\n",
    "    \n",
    "    all_tfidf=[]\n",
    "    all_tf=[]\n",
    "    for query in query_s:\n",
    "        q_tf=tf_(query)\n",
    "        all_tf.append(q_tf)\n",
    "        mac=q_tf.values()\n",
    "        max_tf=max(q_tf.values())\n",
    "        tfidf=[]\n",
    "        for word in c:\n",
    "            if word not in q_tf: # query item does not shown in doc collection\n",
    "                    value=0\n",
    "            else:\n",
    "                value=(1+math.log10(q_tf.get(word)))/(1+math.log10(max_tf))*math.log10(len(allDocument)/df.get(word))\n",
    "           \n",
    "            tfidf.append(value)\n",
    "        all_tfidf.append(tfidf)\n",
    "    return np.array(all_tfidf), all_tf #vector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_query=pd.read_excel('df_query_pre.xlsx')\n",
    "df_doc=pd.read_excel('df_doc_pre.xlsx')\n",
    "\n",
    "doc_col=df_doc.loc[: , \"Text_tok\"].tolist() #collection: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic_df=pd.read_csv('dictionary.csv')\n",
    "doc_fre_df=pd.read_csv('document_frequency.csv')\n",
    "dic=dic_df['0'].tolist()\n",
    "doc_fre=pd.Series(doc_fre_df.df.values,index=doc_fre_df.term).to_dict()\n",
    "q_tfidf,q_tf=tfidf_(df_query[\"Text_tok\"],dic,doc_fre,doc_col) # query tf-idf\n",
    "d_tfidf,d_tf=tfidf_(df_doc[\"Text_tok\"],dic,doc_fre,doc_col) # doc tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tiered index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import time\n",
    "def top_N(K, dataframe, tiers, n, term_key):\n",
    "# K: the number of top documents\n",
    "    quantile=1 # split posting list into several same length parts\n",
    "    for i in range(tiers):\n",
    "        quantile=quantile-1/tiers\n",
    "        if quantile<0:\n",
    "            quantile=0\n",
    "        quantile_value_list=dataframe.quantile(quantile, axis=1)\n",
    "        s=dataframe.sub(quantile_value_list,axis=0)\n",
    "        s=s.where(s>0,0) \n",
    "        s=s.where(s<=0,1) \n",
    "        columns_sum=s.sum()\n",
    "        top_doc_list=[i for i in range(len(columns_sum)) if columns_sum[i] >= n*len(term_key)]\n",
    "\n",
    "        if len(top_doc_list)>=K:\n",
    "            break\n",
    "    return top_doc_list\n",
    "\n",
    "def tiered_index(K, query_tf, documents_tf, tiers, n):\n",
    "    start = time.time()\n",
    "    # query_tf are all the query list\n",
    "    # documents_tf is all the documents list\n",
    "    a=pd.DataFrame(documents_tf).T # dataframe of all documents\n",
    "    top_list=[]\n",
    "    for i in range(len(query_tf)):\n",
    "        term_key=list(query_tf[i].keys())\n",
    "        c=pd.DataFrame(a,index=term_key).fillna(value=0)# dataframe of posting list\n",
    "        List=top_N(K, c, tiers, n, term_key)\n",
    "        top_list.append(List)\n",
    "    end = time.time()\n",
    "    return top_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cosine similarity\n",
    "import time\n",
    "def cosine_similarity_final(q_tfidf,d_tfidf,top_k_list):\n",
    "    start = time.time()\n",
    "    sim_all={}\n",
    "    for q in range(len(q_tfidf)):\n",
    "        sim={}\n",
    "        sim_all[q]=sim\n",
    "        new_d_tfidf=[]\n",
    "        for index in top_k_list[q]:\n",
    "            new_d_tfidf.append(d_tfidf[index])# remain tfidf value of return relevant documents\n",
    "\n",
    "        for d in range(len(new_d_tfidf)):\n",
    "            sim[d+1]=cosine_similarity(new_d_tfidf[d],q_tfidf[q])\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    df_similarity= pd.DataFrame(data=sim_all)\n",
    "    df_similarity['d_index1']=df_similarity.index\n",
    "    df1 = df_similarity.reset_index(drop=True)\n",
    "    df2 = pd.melt(df1, id_vars=[\"d_index1\"], var_name=\"q_index\", value_name=\"similarity\")\n",
    "    df2=df2.dropna()\n",
    "    df2['d_index']=sum(top_k_list, [])\n",
    "    df2 = df2[[\"d_index\",\"q_index\",\"similarity\"]]\n",
    "    df2=df2.sort_values(by=['q_index','similarity'],ascending=[True,False])\n",
    "    df_query['q_index']=df_query.index\n",
    "    df_doc['d_index']=df_doc.index\n",
    "    df2=pd.merge(df2,df_query[['Query id','q_index']],on='q_index',how='left')\n",
    "    df2=pd.merge(df2,df_doc[['Doc id','d_index']],on='d_index',how='left')\n",
    "    df_similarity_final=df2[['Query id', 'Doc id', 'similarity']]\n",
    "    \n",
    "    #change label order\n",
    "    rel_label = pd.read_excel(\"all2-1-0.qrel.xlsx\")\n",
    "    rel_similarity=pd.merge(df_similarity_final[['Query id','Doc id']],rel_label, on=['Query id','Doc id'], how='left')\n",
    "    rel_similarity=rel_similarity.fillna(value=0)\n",
    "    rel_similarity=rel_similarity.drop(['Doc id'],axis=1)\n",
    "    s = rel_similarity.groupby('Query id')['Rel_level'].apply(lambda x: x.tolist())\n",
    "    correct_input=s.values\n",
    "    return correct_input, end-start\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MAP\n",
    "import numpy as np \n",
    "# presicion \n",
    "def precision(y_true):\n",
    "#y_true: this list reordered y_true list\n",
    "    p=[]\n",
    "    a=0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i]==1:\n",
    "            a+=1\n",
    "            precision=a/(i+1)\n",
    "            p.append(precision)\n",
    "    #print(p)\n",
    "    return p\n",
    "\n",
    "# average precision\n",
    "def AP(y_true):\n",
    "    p=precision(y_true)\n",
    "    if len(p)!=0:\n",
    "        AP=sum(p)/len(p)\n",
    "    else:\n",
    "        AP=0\n",
    "    #print(AP)\n",
    "    return AP\n",
    "\n",
    "\n",
    "def MAP(list_true):# query list \n",
    "    ap=[]\n",
    "    for i in range(len(list_true)):\n",
    "        ap.append(AP(list_true[i]))\n",
    "    total=sum(ap)\n",
    "    #print(ap)\n",
    "    return total/(len(list_true))\n",
    "#print(MAP(correct_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NDCG\n",
    "import numpy as np \n",
    "def ndcg(correct):\n",
    "    dcg=0\n",
    "    for i in range(len(correct)):\n",
    "        gain=2**correct[i]-1\n",
    "        discounts=np.log2(i+2)\n",
    "        dcg=dcg+gain/discounts\n",
    "    \n",
    "    #idcg\n",
    "    order = np.argsort(correct)\n",
    "    sort_correct = np.take(correct, order[::-1])\n",
    "    idcg=0\n",
    "    for i in range(len(sort_correct)):\n",
    "        gain=2**sort_correct[i]-1\n",
    "        discounts=np.log2(i+2)\n",
    "        idcg=idcg+gain/discounts\n",
    "    #print(dcg)\n",
    "    #print(idcg)\n",
    "    if idcg==0:\n",
    "        c=0\n",
    "    else:\n",
    "        c=dcg/idcg\n",
    "    return c\n",
    "\n",
    "def mean_ndcg(correct_list):\n",
    "    b=0\n",
    "    for correct in correct_list:\n",
    "        a=ndcg(correct)\n",
    "        b=b+a\n",
    "    return b/len(correct_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# whole process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def whole_process(K,q_tf,d_tf,tiers,q_tfidf,d_tfidf,precision_list):\n",
    "    time=[]\n",
    "    MAP_value=[]\n",
    "    ndcg_value=[]\n",
    "\n",
    "    \n",
    "    for value in precision_list:\n",
    "        top_k_list=tiered_index(K, q_tf,d_tf, tiers, value)\n",
    "\n",
    "        correct_input,time_similarity=cosine_similarity_final(q_tfidf, d_tfidf, top_k_list)\n",
    "        time.append(time_similarity)\n",
    "        MAP_value.append(MAP(correct_input))\n",
    "        ndcg_value.append(mean_ndcg(correct_input))\n",
    "        \n",
    "    frame=pd.DataFrame(data=[time,MAP_value,ndcg_value],columns=precision_list,index=['time','MAP','NDCG'])\n",
    "    return frame\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "tiers=3\n",
    "precision_list=[0.06]\n",
    "K=50\n",
    "a=whole_process(K,q_tf,d_tf,tiers,q_tfidf,d_tfidf,precision_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0.06\n",
      "time  130.249000\n",
      "MAP     0.157727\n",
      "NDCG    0.461134\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For testing:\n",
    "# There are three varibles: \n",
    "# 1.Number of tier\n",
    "# 2.Required percentage of query terms a document contains \n",
    "#   This a percentage value list, user can put diferent value in it and see their \n",
    "#   corresponding result\n",
    "# 3.Top K value\n",
    "\n",
    "#-----------------------------------------------\n",
    "# This is the code for testing:\n",
    "#-----------------------------------------------\n",
    "#tiers= \n",
    "#precision_list=[ ]\n",
    "#K=\n",
    "#a=whole_process(K,q_tf,d_tf,tiers,q_tfidf,d_tfidf,precision_list)\n",
    "#print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
